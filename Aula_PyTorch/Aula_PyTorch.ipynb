{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AulaInterna_PyTorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpQ2lNMgNM0f"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=10ktSa_7Q-A6sgBICdiN9DhAns1vrjxVo\" width=\"500\">\n",
        "\n",
        "## Aula interna de PyTorch\n",
        "\n",
        "> *Autores: Edu, Enzo, Paulo e Wesley*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cP34UZULI6B"
      },
      "source": [
        "## Tensores\n",
        "\n",
        "Antes de começar a implementar códigos e trabalharmos em cima das propriedades dos tensores em Torch acho importante em um primeiro momento esclarecermos duas perguntas: O que é um tensor? E, qual a diferença de tensores em NumPy e em PyTorch ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6NjBqHhIadw"
      },
      "source": [
        "### 1. O que são tensores ?\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1-XwvVjLsNe8Gj_cABRVwXlsz8hEW3t-R\" width='500'>\n",
        "\n",
        "Tensores são uma generalização do conceito de escalares (0D), vetores (1D) e matrizes (2D) para maiores dimensões, embora haja alguns detalhes entre a definição matemática e o que realmente usamos pode-se dizer que um tensor é um *conteiner* de dados em N dimensões e geralmente nos referimos a um tensor quando existem 3 ou mais dimensões envolvidas.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1AUtY7PNJdplrI0sqSghcG8oUSZpurenJ\" width=\"500\">\n",
        "\n",
        "**FUEN FUEN FUEN ALERTA DE NERD !!!**\n",
        "\n",
        "Entrando em um ponto um pouco mais técnico, além dos dados que o tensor consegue segurar, a ele também estão definidos algumas transformações lineares válidas entre tensores como o produto escalar ($\\cdot$) e o produto vetorial ($\\times$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PK6RWLCIeAB"
      },
      "source": [
        "### 2. Numpy vs. Torch\n",
        "\n",
        "Agora falando um pouco mais computacionalmente, tensores em PyTorch são extremamente semelhantes aos `ndarrays` do NumPy quanto ao quesito de manipulação e operações que você pode realizar, porém um ponto crucial da vantagem do PyTorch é que estes tensores podem ser processados em GPU (Unidade de Processamento Gráfica), que torna os cálculos envolvidos dentro de Machine Learning bem mais rápido pelo falo das GPUs serem otimizadas para paralelização, ou seja, podem realizar vários cálculos simultâneamente.\n",
        "\n",
        "Acho que o melhor jeito de explicar isso é assistindo [este vídeo](https://www.youtube.com/watch?v=-P28LKWTzrI)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kwypvu9LYfa"
      },
      "source": [
        "## Propriedades dos Tensores\n",
        "\n",
        "Nessa parte a ideia principal é mostrar um pouco como são feitas as manipulações desses tensores e algumas operações interessantes que o PyTorch propicia, principalmente a integração dos tensores em PyTorch serem contemplados pelas tecnologias de GPU, podendo ser processados muito mais rapidamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n5Sq_vV_PiS"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j_YArCi_wld"
      },
      "source": [
        "### 1. Declaração de tensores\n",
        "\n",
        "Existem várias formas de se declararem os tensores em PyTorch, podendo desde alocar um espaço vazio, iniciar uma matriz aleatória, definir ser próprio tensor a partir de arranjo de listas em Python e ainda ter uma comunicação com as funcionalidades de NumPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkNc4UycLuAs"
      },
      "source": [
        "Primeiro vou começar só mostrando algumas funções que podem ser úteis ocasionalmente, porém bem por cima já que o foco é justamente usar as integrações com NumPy para fazermos *machine learning*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD-j1oIKLqIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "484b01a1-cba8-44dd-fb8f-d039028a159e"
      },
      "source": [
        "x = torch.empty(5, 3) #Inicia um vetor com valores não inicializados --> com os valores que já estavam naquela posição da memória\n",
        "y =  torch.rand(5, 3) #Inicia um vetor com valores aleatórios\n",
        "z = torch.randn(5, 3) #Inicia um vetor com valores aleatórios Normalmente distribuídos\n",
        "i =  torch.ones(5, 3) #Inicia um vetor de 1s\n",
        "j = torch.zeros(5, 3) #Inicia um vetor de 0s\n",
        "\n",
        "print(\"Tensor x: \\n\" + str(x), end='\\n\\n')\n",
        "print(\"Tensor y: \\n\" + str(y), end='\\n\\n')\n",
        "print(\"Tensor z: \\n\" + str(z), end='\\n\\n')\n",
        "print(\"Tensor i: \\n\" + str(i), end='\\n\\n')\n",
        "print(\"Tensor j: \\n\" + str(j), end='\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor x: \n",
            "tensor([[3.5610e-35, 0.0000e+00, 3.3631e-44],\n",
            "        [0.0000e+00,        nan, 0.0000e+00],\n",
            "        [1.1578e+27, 1.1362e+30, 7.1547e+22],\n",
            "        [4.5828e+30, 1.2121e+04, 7.1846e+22],\n",
            "        [9.2198e-39, 7.0374e+22, 1.1799e-35]])\n",
            "\n",
            "Tensor y: \n",
            "tensor([[0.9233, 0.1643, 0.0775],\n",
            "        [0.4079, 0.8822, 0.2316],\n",
            "        [0.6112, 0.7398, 0.4804],\n",
            "        [0.8606, 0.8694, 0.0656],\n",
            "        [0.2568, 0.7682, 0.5517]])\n",
            "\n",
            "Tensor z: \n",
            "tensor([[ 8.7006e-01,  7.5909e-01,  3.3861e-01],\n",
            "        [ 1.8587e-01,  6.8591e-01, -3.0263e-01],\n",
            "        [-4.0563e-01,  8.2349e-01, -4.9515e-01],\n",
            "        [ 1.9382e-04,  3.3928e-01,  3.6205e-01],\n",
            "        [ 5.3234e-01, -1.3152e+00, -9.7296e-01]])\n",
            "\n",
            "Tensor i: \n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "\n",
            "Tensor j: \n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGHBHBG4MN-K"
      },
      "source": [
        "Apesar dessas funções serem úteis o mais interessante é você poder fazer essa integração para tensores a partir dos seus próprios dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQYFY_5bMRjY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa42789-ee8a-448f-83eb-85361eaba17b"
      },
      "source": [
        "exemplo = torch.tensor(\n",
        "    [\n",
        "     [[1, 2], [3, 4]], \n",
        "     [[5, 6], [7, 8]], \n",
        "     [[9, 0], [1, 2]],\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(exemplo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]],\n",
            "\n",
            "        [[9, 0],\n",
            "         [1, 2]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPWNszasMVXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57eba3e3-fdf5-49b0-d0c7-aa72127f1b68"
      },
      "source": [
        "#Podemos ainda fazer uma integração entre NumPy e PyTorch com muita facilidade\n",
        "\n",
        "a = torch.ones(3, 2, 2)\n",
        "b = a.numpy() #Converte de tensor --> ndarray\n",
        "\n",
        "print(\"a:\", type(a), \"\\nb:\", type(b))\n",
        "\n",
        "c = np.ones((3, 2, 2))\n",
        "d = torch.from_numpy(c) #Converte de ndarray --> tensor\n",
        "\n",
        "print(\"\\nc:\", type(c), \"\\nd:\", type(d))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a: <class 'torch.Tensor'> \n",
            "b: <class 'numpy.ndarray'>\n",
            "\n",
            "c: <class 'numpy.ndarray'> \n",
            "d: <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvQL0GDbMZgF"
      },
      "source": [
        "### 2. Operações com os tensores\n",
        "\n",
        "Com os tensores a principal ideia é fazer operações matemáticas com eles, para isso a maioria das operações já conhecidas do NumPy como multiplicações e adições podem ser facilmente utilizadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N0M0R9rMeb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae7917c9-1d55-4985-92a7-3daac14d243f"
      },
      "source": [
        "tensor_1 = torch.tensor(\n",
        "    [\n",
        "     [1, 2],\n",
        "     [3, 4],\n",
        "    ], dtype=torch.float64 #Especifíca o tipo do tensor como de floats\n",
        ")\n",
        "\n",
        "tensor_2 = torch.tensor(\n",
        "    [\n",
        "     [5, 6],\n",
        "     [7, 8]\n",
        "    ], dtype=torch.float64\n",
        ")\n",
        "\n",
        "print(tensor_1, \"---> Tensor 1\")\n",
        "print()\n",
        "print(tensor_2, \"---> Tensor 2\")\n",
        "print()\n",
        "print(torch.add(tensor_1, tensor_2), \"---> Soma de tensores\")\n",
        "print()\n",
        "print((torch.add(tensor_1, tensor_2) - 5)*2, \"---> Operações elemento a elemento\")\n",
        "print()\n",
        "print(tensor_1.mean(), \"---> Média\")\n",
        "print()\n",
        "print(tensor_2.std(), \"---> Desvio Padrão\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]], dtype=torch.float64) ---> Tensor 1\n",
            "\n",
            "tensor([[5., 6.],\n",
            "        [7., 8.]], dtype=torch.float64) ---> Tensor 2\n",
            "\n",
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]], dtype=torch.float64) ---> Soma de tensores\n",
            "\n",
            "tensor([[ 2.,  6.],\n",
            "        [10., 14.]], dtype=torch.float64) ---> Operações elemento a elemento\n",
            "\n",
            "tensor(2.5000, dtype=torch.float64) ---> Média\n",
            "\n",
            "tensor(1.2910, dtype=torch.float64) ---> Desvio Padrão\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ePgB3SiMhhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9409409d-f46f-4a1f-fdd9-259e357cec7e"
      },
      "source": [
        "flat_1 = torch.flatten(tensor_1) #Função que converte o tensor em um tensor 1D\n",
        "flat_2 = tensor_1.view([4]) #É possível usar também a funçar view para redimensionar\n",
        "\n",
        "print(flat_1, \"---> Flat 1\")\n",
        "print()\n",
        "print(flat_2, \"---> Flat 2\")\n",
        "print()\n",
        "print(torch.dot(flat_1, flat_2), \"---> Produto escalar\")\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3., 4.], dtype=torch.float64) ---> Flat 1\n",
            "\n",
            "tensor([1., 2., 3., 4.], dtype=torch.float64) ---> Flat 2\n",
            "\n",
            "tensor(30., dtype=torch.float64) ---> Produto escalar\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ4YC3BgBtkh"
      },
      "source": [
        "O PyTorch ainda pode receber uma função do tipo `operation_` esse `_` indica uma operação *inplace*, ou seja, ela altera o tensor passado ao invés de criar um novo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOGyfl61Bzze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca04ae62-7f58-4cf5-e805-b2e544098815"
      },
      "source": [
        "#Existem diversas sintaxes para fazer uma mesma operação\n",
        "\n",
        "print(\"tensor_1 + tensor_2\")\n",
        "print(tensor_1 + tensor_2, end='\\n\\n')\n",
        "\n",
        "print(\"torch.add(tensor_1, tensor_2)\")\n",
        "print(torch.add(tensor_1, tensor_2), end='\\n\\n')\n",
        "\n",
        "print(\"tensor_1.add_(tensor_2) --> Operação inplace\")\n",
        "print(tensor_1.add_(tensor_2), end='\\n\\n')\n",
        "\n",
        "print(\"tensor_1 --> Tensor mudou\")\n",
        "print(tensor_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor_1 + tensor_2\n",
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]], dtype=torch.float64)\n",
            "\n",
            "torch.add(tensor_1, tensor_2)\n",
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]], dtype=torch.float64)\n",
            "\n",
            "tensor_1.add_(tensor_2) --> Operação inplace\n",
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]], dtype=torch.float64)\n",
            "\n",
            "tensor_1 --> Tensor mudou\n",
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnVgtDk8Ir3r"
      },
      "source": [
        "## CUDA tensors\n",
        "\n",
        "Uma das principais vantagens de se utilizar PyTorch é que os tensores podem ser processados dentro das GPUs (unidade gráfica que acelera as computações) e isso acelera bastante todas as operações tensoriais, mas veremos isso com mais detalhes um pouco a frente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ-xzKofJ4Ls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "778d1c21-6c96-4b3e-da32-081e966ac862"
      },
      "source": [
        "#Checa se GPU está disponível\n",
        "#Para o Colab você deve checar se seu ambiente está com GPU ativada\n",
        "\n",
        "print(\"GPU disponível ?:\", torch.cuda.is_available())\n",
        "\n",
        "tensor = torch.tensor(\n",
        "    [\n",
        "     [[1, 2], [3, 4]], \n",
        "     [[5, 6], [7, 8]], \n",
        "     [[9, 0], [1, 2]]\n",
        "    ],\n",
        "    device = 'cuda' #Permite que o tensor seja operado na GPU\n",
        ")\n",
        "\n",
        "print(\"Dispositivo do meu tensor:\", tensor.device)\n",
        "\n",
        "#Método para alterar o dispositivo\n",
        "tensor_cpu = tensor.to(torch.device('cpu'))\n",
        "\n",
        "print(\"Dispositivo do meu tensor:\", tensor_cpu.device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU disponível ?: True\n",
            "Dispositivo do meu tensor: cuda:0\n",
            "Dispositivo do meu tensor: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwTgaN8vM5HL"
      },
      "source": [
        "## O que faz o PyTorch ser capaz de treinar redes neurais?\n",
        "\n",
        "O ponto central do PyTorch é a capacidade de realizar diferenciação automática, mais especificamente, backpropagation, que é feito pelo módulo interno da biblioteca chamado autograd, o que permite treinar os modelos.\n",
        "\n",
        "Para isto, ao realizar operações com tensores, um grafo computacional é criado para registrar as operações feitas e, assim, realizar backpropagation para calcular os gradientes em relação aos tensores necessários."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kar9OkcuM9_x"
      },
      "source": [
        "## Exemplo de diferenciação automática\n",
        "\n",
        "Observe a expressão $z = x^2 + 3y$\n",
        "\n",
        "Ela pode ser representada por meio do seguinte grafo\n",
        "\n",
        "\n",
        "<img width=\"25%\" src=\"https://i.ibb.co/c1728sz/graph-1.png\"/>\n",
        "\n",
        "Agora imagine que nós queiramos calcular as derivadas $\\frac{\\partial z}{\\partial x}$ e $\\frac{\\partial z}{\\partial y}$, quando $ x = 3 $ e $ y = 4 $.\n",
        "\n",
        "Para isto, iremos utilização o algoritmo de backpropagation, ou diferenciação automática reversa, onde partimos do final do gráfico e seguimos o caminho contrário até chegar na variável de interesse, no caso, $ x $ e $ y $.\n",
        "\n",
        "Para facilitar na compreensão de como a retropagação de gradientes é feita, iremos introduzir as variáveis auxiliares $a$ e $b$\n",
        "\n",
        "<img width=\"25%\" src=\"https://i.ibb.co/hchh8Qn/graph-2.png\"/>\n",
        "\n",
        "Dessa forma, nós temos as seguintes expressões:\n",
        "\n",
        "$z = a + b$\n",
        "\n",
        "$a = x^2$\n",
        "\n",
        "$b = 3y$\n",
        "\n",
        "Primeiramente, calculamos $ \\frac{\\partial z}{\\partial a} = 1 $ e $ \\frac{\\partial z}{\\partial b} = 1$.\n",
        "\n",
        "Em seguida, calculamos $ \\frac{\\partial a}{\\partial x} = 2x = 2*3 = 6 $ e $ \\frac{\\partial b}{\\partial y} = 3$.\n",
        "\n",
        "Finalmente, utilizando a regra da cadeia podemos obter:\n",
        "\n",
        "$\\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial a} * \\frac{\\partial a}{\\partial x} = 1 * 6 = 6$\n",
        "\n",
        "$\\frac{\\partial z}{\\partial y} = \\frac{\\partial z}{\\partial b} * \\frac{\\partial b}{\\partial y} = 1 * 3 = 3$\n",
        "\n",
        "<img src=\"https://i.ibb.co/MkBk7jn/graph-3.png\"/>\n",
        "\n",
        "Aqui, escolhemos um exemplo simples para explicar facilmente o algoritmo, porém é possível ver como ele facilmente se estende para expressões muito longas e complicadas, como as que ocorrem em redes neurais, quebrando o cálculo dos gradientes em pequenos cálculos menores ao longo do grafo, obtendo o resultado esperado através da aplicação da regra da cadeia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ztuqj_8nNECg"
      },
      "source": [
        "## Mesmo exemplo em PyTorch\n",
        "Agora veremos como podemos calcular o exemplo dado com a biblioteca."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC--OZApNHYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a7ffb2-a8dc-4278-a564-5378357fabbd"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Criamos os tensores com os valores desejados (x = 3 e y = 4).\n",
        "# Para que o PyTorch crie o grafo computacional para o calculo do gradiente,\n",
        "# Precisamos explicitar que desejamos calcular os gradientes em relação a estes tensores\n",
        "# Através do parâmetro requires_grad\n",
        "x = torch.tensor([3.0], requires_grad=True)\n",
        "y = torch.tensor([4.0], requires_grad=True)\n",
        "\n",
        "# Realizamos o cálculo necessário\n",
        "z = x**2 + 3*y\n",
        "\n",
        "# Executamos a operação de retropropagação\n",
        "z.backward() # Retropropagando a partir de z\n",
        "\n",
        "# Os gradientes ficam guardados nos atributos .grad dos\n",
        "# respectivos tensores\n",
        "dzdx = x.grad\n",
        "dzdy = y.grad\n",
        "print(f\"z = {z}, \\n dz/dx = {dzdx}, \\n dz/dy = {dzdy}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z = tensor([21.], grad_fn=<AddBackward0>), \n",
            " dz/dx = tensor([6.]), \n",
            " dz/dy = tensor([3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fXumOzPUsPe"
      },
      "source": [
        "## Criando uma rede neural em Torch\n",
        "Redes neurais no PyTorch são construídos utilizando o pacote <code>torch.nn</code>.\n",
        "A forma mais simples e organizada de criar uma rede neural em PyTorch é implementando uma classe nos moldes da classe <code>nn.Module</code>, ou seja, uma classe que herda da classe <code>nn.Module</code>. <br>\n",
        "Funções obrigatórias do <code>nn.Module</code>: <br>\n",
        "```__init()__```: definição de hiperparâmetros e instância do modelo <br>\n",
        "```forward()```: Fluxo da entrada para produzir uma saída\n",
        "\n",
        "Rede a ser implementada: <br>\n",
        "<img src=\"https://i.imgur.com/tC1EAbU.jpg\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQSMvaAkZYiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb2e61b6-f3dd-4ff7-ce5f-c0d348e459fb"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RedeSimples(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(RedeSimples, self).__init__()\n",
        "\n",
        "        # Definição das camadas convolucionais\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6,  out_channels=12, kernel_size=5)\n",
        "        \n",
        "        # Definição das camadas fc\n",
        "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "        self.out = nn.Linear(in_features=60, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # 1ª camada convolucional\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        # 2ª camada convolucional\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        # Redimensionamento da matriz para camadas fc\n",
        "        x = x.reshape(-1, 12*4*4)\n",
        "        \n",
        "        # 1ª camada totalmente conectada\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # 2ª camada totalmente conectada\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Camada totalmente conectada de saída\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "rede = RedeSimples()\n",
        "print(rede)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RedeSimples(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
            "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqZKwKwZZL8t"
      },
      "source": [
        "## Datasets no PyTorch\n",
        "O PyTorch possui 2 pacotes que possuem datasets para utilização. São eles:\n",
        "- [torchtext](!https://torchtext.readthedocs.io/en/latest/datasets.html)\n",
        "- [torchvision](!https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
        "\n",
        "### Carregando um dataset do torchvision\n",
        "Para poder utilizar os datasets existentes no <code>torchvision</code> basta importar o módulo e carregar o dataset de interesse:\n",
        "```[Python]\n",
        "from torchvision import datasets\n",
        "data = datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM8AZopYcDAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d500a07-7466-42ed-ca16-ab0d7a880118"
      },
      "source": [
        "from torchvision import datasets\n",
        "from torchvision import transforms \n",
        "\n",
        "dados_treino = datasets.FashionMNIST(root = './data/FashionMNIST', \n",
        "                                    train=True, \n",
        "                                    transform=transforms.Compose([\n",
        "                                        transforms.ToTensor()\n",
        "                                    ]),\n",
        "                                    download=True)\n",
        "\n",
        "dados_teste = datasets.FashionMNIST(root='./data/FashionMNIST', \n",
        "                                    train=False, \n",
        "                                    transform=transforms.ToTensor(),\n",
        "                                    download=True)\n",
        "\n",
        "print('Número de amostras de treino: ' + str(len(dados_treino)))\n",
        "print('Número de amostras de teste:  ' + str(len(dados_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número de amostras de treino: 60000\n",
            "Número de amostras de teste:  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpw9yPc8dp10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "afe052ad-dc9c-4911-eb04-58a2654a1ac0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(2):\n",
        "  dado, rotulo = dados_treino[i]\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(dado[0], cmap='gray')\n",
        "  plt.title('Rotulo: '+ str(rotulo))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUIUlEQVR4nO3de6zU5Z3H8fdXxAsXuYjgAVnRipGmsbAiGkXjPWhTb22wJttgtEujNVmzmq7rNquJf2i0l202tg1Vo9auXTfVrcZbqdlddwOtHA0L6NkqKCwgHFAUOYjAwe/+MT+as3h+3+cwvzkzA8/nlRDOme95Zp6Z4cPMme/v+T3m7ojIwe+QVk9ARJpDYRfJhMIukgmFXSQTCrtIJhR2kUwo7JJkZneZ2eOtnodUo7AfoMxstZntMLMeM9toZo+Y2Yj9GHvRYM+x5LbPMrNXzWybmS0zs9mtmEeOFPYD21fdfQQwHZgB/G2L5xMys7HAs8D9wGjgPuBZMxvT0ollQmE/CLj7RuAlaqEHwMwuN7M3zOwjM/t3M5tWXP4L4M+ohazHzL5rZueZ2bq+1xm9+pdd9wCcBWx0939x9z3u/jiwGbh6/++17C+F/SBgZscBlwIri+9PBp4AbgGOAZ6nFu7D3P2bwP9SvCtw9/v287ZKr7uo/8TMfhJdRT/ff2l/5iD1UdgPbP9qZtuAtcAm4M7i8muA59x9obvvBr4PHEntlbWq8Lrd/SZ3v6lk7GJgoplda2ZDzWwe8AVgWAPmJQkK+4HtSncfCZwHnAKMKy6fCKzZ+0Pu/hm1/xAmNeA2675ud/8AuAL4a6AbmAP8DlgXjZPGUNgPAu7+H8Aj1F5lAd4Djt9bNzMDJgPr9w7Z5yq20+fV1cyGUHuL3p/UdSfn6u6nu/tY4JvU/pN6dSBjpRqF/eDxD8DFZvZl4EngK2Z2oZkNBW4FdgKLip/tBk7sM/Yt4Agz+0rx898DDi+5ndR1h8xsRvEW/ihq/zmtdfeX9uueSl0U9oOEu28GHgP+3t3/CPwF8I/A+8BXqX0gt6v48XuA7xWfpt/m7luBm4AHqb1Cb6fkrXXqus3sZ2b2s2Cq3y3GrQU6gKvqv9eyP0wnrxDJg17ZRTKhsItkQmEXyYTCLpKJQ5t5Y2amTwNFBpm773tIMlDxld3M5pjZH81spZndXuW6RGRw1d16K46yegu4mFpPdglwrbu/GYzRK7vIIBuMV/ZZwEp3f6c4oOJX1I57FpE2VCXsk6gdBbXXOvpZDGFm882s08w6K9yWiFQ06B/QufsCYAHobbxIK1V5ZV9PbbXTXscxwJVPItJ8VcK+BJhqZicUZyn5BvBMY6YlIo1W99t4d+81s5upnftsCPCwu7/RsJmJSEM1ddWbfmcXGXyDclCNiBw4FHaRTCjsIplQ2EUyobCLZEJhF8mEwi6SCYVdJBMKu0gmFHaRTCjsIplQ2EUyobCLZKKpp5KW5qvtqFyu6qrHkSNHhvXZs2eX1l544YVKt526b0OGDCmt9fb2VrrtqlJzj9T7nOmVXSQTCrtIJhR2kUwo7CKZUNhFMqGwi2RCYRfJhPrsB7lDDon/P9+zZ09YP+mkk8L6t771rbC+Y8eO0tr27dvDsZ9++mlYf/XVV8N6lV56qg+eelxT46vMLTp+IHo+9coukgmFXSQTCrtIJhR2kUwo7CKZUNhFMqGwi2RCffaDXNSThXSf/YILLgjrF110UVhft25dae3www8Pxw4bNiysX3zxxWH9wQcfLK11d3eHY1NrxlOPW8qIESNKa5999lk49pNPPqnrNiuF3cxWA9uAPUCvu8+scn0iMnga8cp+vru/34DrEZFBpN/ZRTJRNewO/NbMXjOz+f39gJnNN7NOM+useFsiUkHVt/Gz3X29mY0HFprZ/7j7K31/wN0XAAsAzKza2Q1FpG6VXtndfX3x9ybgaWBWIyYlIo1Xd9jNbLiZjdz7NXAJsKJRExORxqryNn4C8HSxbvdQ4J/c/cWGzEoaZteuXZXGn3766WF9ypQpYT3q86fWhL/00kthfcaMGWH9vvvuK611dsYfIS1fvjysd3V1hfVZs+I3udHjumjRonDs4sWLS2s9PT2ltbrD7u7vAF+ud7yINJdabyKZUNhFMqGwi2RCYRfJhMIukgmrumXvft2YjqAbFNFpi1PPb2qZaNS+Ahg9enRY3717d2kttZQzZcmSJWF95cqVpbWqLcmOjo6wHt1viOf+9a9/PRz7wAMPlNY6Ozv5+OOP+/0HoVd2kUwo7CKZUNhFMqGwi2RCYRfJhMIukgmFXSQT6rO3gdT2vlWknt/f//73YT21hDUlum+pbYur9sKjLZ9TPf7XX389rEc9fEjftzlz5pTWTjzxxHDspEmTwrq7q88ukjOFXSQTCrtIJhR2kUwo7CKZUNhFMqGwi2RCWza3gWYe67CvDz/8MKyn1m3v2LEjrEfbMh96aPzPL9rWGOI+OsCRRx5ZWkv12c8555ywftZZZ4X11Gmyx48fX1p78cXBOSO7XtlFMqGwi2RCYRfJhMIukgmFXSQTCrtIJhR2kUyoz565YcOGhfVUvzhV/+STT0prW7duDcd+8MEHYT211j46fiF1DoHU/Uo9bnv27AnrUZ9/8uTJ4dh6JV/ZzexhM9tkZiv6XDbWzBaa2dvF32MGZXYi0jADeRv/CLDvaTVuB15296nAy8X3ItLGkmF391eALftcfAXwaPH1o8CVDZ6XiDRYvb+zT3D3DcXXG4EJZT9oZvOB+XXejog0SOUP6NzdoxNJuvsCYAHohJMirVRv663bzDoAir83NW5KIjIY6g37M8C84ut5wG8aMx0RGSzJt/Fm9gRwHjDOzNYBdwL3Ak+a2Q3AGmDuYE7yYFe15xv1dFNrwidOnBjWd+7cWakerWdPnRc+6tFDem/4qE+f6pMfdthhYX3btm1hfdSoUWF92bJlpbXUczZz5szS2ptvvllaS4bd3a8tKV2YGisi7UOHy4pkQmEXyYTCLpIJhV0kEwq7SCa0xLUNpE4lPWTIkLAetd6uueaacOyxxx4b1jdv3hzWo9M1Q7yUc/jw4eHY1FLPVOsuavvt3r07HJs6zXXqfh999NFh/YEHHiitTZ8+PRwbzS1q4+qVXSQTCrtIJhR2kUwo7CKZUNhFMqGwi2RCYRfJhDVzu2CdqaZ/qZ5ub29v3dd9xhlnhPXnnnsurKe2ZK5yDMDIkSPDsaktmVOnmh46dGhdNUgfA5Da6jolum/3339/OPbxxx8P6+7eb7Ndr+wimVDYRTKhsItkQmEXyYTCLpIJhV0kEwq7SCYOqPXs0VrdVL83dTrm1Omco/XP0ZrtgajSR095/vnnw/r27dvDeqrPnjrlcnQcR2qtfOo5PeKII8J6as16lbGp5zw191NPPbW0ltrKul56ZRfJhMIukgmFXSQTCrtIJhR2kUwo7CKZUNhFMtFWffYqa6MHs1c92M4999yw/rWvfS2sn3322aW11LbHqTXhqT56ai1+9Jyl5pb69xCdFx7iPnzqPA6puaWkHreenp7S2tVXXx2OffbZZ+uaU/KV3cweNrNNZraiz2V3mdl6M1ta/LmsrlsXkaYZyNv4R4A5/Vz+I3efXvyJD9MSkZZLht3dXwG2NGEuIjKIqnxAd7OZLSve5o8p+yEzm29mnWbWWeG2RKSiesP+U+ALwHRgA/CDsh909wXuPtPdZ9Z5WyLSAHWF3d273X2Pu38G/ByY1dhpiUij1RV2M+vo8+1VwIqynxWR9pA8b7yZPQGcB4wDuoE7i++nAw6sBr7t7huSN9bC88aPHTs2rE+cODGsT506te6xqb7pySefHNZ37twZ1qO1+ql12al9xt97772wnjr/etRvTu1hntp/fdiwYWF90aJFpbURI0aEY1PHPqTWs6fWpEePW3d3dzh22rRpYb3svPHJg2rc/dp+Ln4oNU5E2osOlxXJhMIukgmFXSQTCrtIJhR2kUy01ZbNZ555Zjj+7rvvLq0dc8wx4djRo0eH9WgpJsTLLT/66KNwbGr5baqFlGpBRafBTp0KuqurK6zPnTs3rHd2xkdBR9syjxlTepQ1AFOmTAnrKe+8805pLbVd9LZt28J6aglsqqUZtf6OOuqocGzq34u2bBbJnMIukgmFXSQTCrtIJhR2kUwo7CKZUNhFMtH0PnvUr168eHE4vqOjo7SW6pOn6lVOHZw65XGq113VqFGjSmvjxo0Lx1533XVh/ZJLLgnrN954Y1iPlsh++umn4dh33303rEd9dIiXJVddXpta2pvq40fjU8tnjz/++LCuPrtI5hR2kUwo7CKZUNhFMqGwi2RCYRfJhMIukomm9tnHjRvnl19+eWn93nvvDcevWrWqtJY6NXCqntr+N5LquUZ9cIC1a9eG9dTpnKO1/NFppgGOPfbYsH7llVeG9WhbZIjXpKeek9NOO61SPbrvqT566nFLbcmcEp2DIPXvKTrvw8aNG9m1a5f67CI5U9hFMqGwi2RCYRfJhMIukgmFXSQTCrtIJpK7uJrZZOAxYAK1LZoXuPuPzWws8M/AFGrbNs919w+j6+rt7WXTpk2l9VS/OVojnNrWOHXdqZ5v1FdNned7y5YtYX3NmjVhPTW3aL18as146pz2Tz/9dFhfvnx5WI/67KlttFO98NT5+qPtqlP3O7WmPNULT42P+uypHn60xXf0mAzklb0XuNXdvwicCXzHzL4I3A687O5TgZeL70WkTSXD7u4b3P314uttQBcwCbgCeLT4sUeB+FArEWmp/fqd3cymADOAPwAT3H1DUdpI7W2+iLSpAYfdzEYAvwZucfeP+9a8doB9vwfZm9l8M+s0s87U72AiMngGFHYzG0ot6L9096eKi7vNrKOodwD9fvLm7gvcfaa7z6y6eEBE6pcMu9U+NnwI6HL3H/YpPQPMK76eB/ym8dMTkUZJtt6As4FvAsvNbGlx2R3AvcCTZnYDsAaI9/al1kpZv359aT213HbdunWlteHDh4djU6dUTrVx3n///dLa5s2bw7GHHho/zKnltak2T7TMNHVK49RSzuh+A0ybNi2sb9++vbSWaod++GHYyU0+btHco7YcpFtzqfGpLZujpcVbt24Nx06fPr20tmLFitJaMuzu/l9AWVPwwtR4EWkPOoJOJBMKu0gmFHaRTCjsIplQ2EUyobCLZGIgffaG2bFjB0uXLi2tP/XUU6U1gOuvv760ljrdcmp739RS0GiZaaoPnuq5po4sTG0JHS3vTW1VnTq2IbWV9YYNG8J6dP2puaWOT6jynFVdPltleS3EffwTTjghHNvd3V3X7eqVXSQTCrtIJhR2kUwo7CKZUNhFMqGwi2RCYRfJRFO3bDazSjd26aWXltZuu+22cOz48ePDemrddtRXTfWLU33yVJ891W+Orj86ZTGk++ypYwhS9ei+pcam5p4SjY961QORes5Sp5KO1rMvW7YsHDt3bnzqCHfXls0iOVPYRTKhsItkQmEXyYTCLpIJhV0kEwq7SCaa3mePzlOe6k1Wcf7554f1e+65J6xHffpRo0aFY1PnZk/14VN99lSfPxJtoQ3pPny0DwDEz2lPT084NvW4pERzT603T63jTz2nCxcuDOtdXV2ltUWLFoVjU9RnF8mcwi6SCYVdJBMKu0gmFHaRTCjsIplQ2EUykeyzm9lk4DFgAuDAAnf/sZndBfwlsHdz8jvc/fnEdTWvqd9Ep5xySlivujf8cccdF9ZXr15dWkv1k1etWhXW5cBT1mcfyCYRvcCt7v66mY0EXjOzvUcM/Mjdv9+oSYrI4EmG3d03ABuKr7eZWRcwabAnJiKNtV+/s5vZFGAG8IfiopvNbJmZPWxmY0rGzDezTjPrrDRTEalkwGE3sxHAr4Fb3P1j4KfAF4Dp1F75f9DfOHdf4O4z3X1mA+YrInUaUNjNbCi1oP/S3Z8CcPdud9/j7p8BPwdmDd40RaSqZNitdorOh4Aud/9hn8s7+vzYVcCKxk9PRBplIK232cB/AsuBvesV7wCupfYW3oHVwLeLD/Oi6zooW28i7aSs9XZAnTdeRNK0nl0kcwq7SCYUdpFMKOwimVDYRTKhsItkQmEXyYTCLpIJhV0kEwq7SCYUdpFMKOwimVDYRTKhsItkYiBnl22k94E1fb4fV1zWjtp1bu06L9Dc6tXIuR1fVmjqevbP3bhZZ7uem65d59au8wLNrV7NmpvexotkQmEXyUSrw76gxbcfade5teu8QHOrV1Pm1tLf2UWkeVr9yi4iTaKwi2SiJWE3szlm9kczW2lmt7diDmXMbLWZLTezpa3en67YQ2+Tma3oc9lYM1toZm8Xf/e7x16L5naXma0vHrulZnZZi+Y22cz+zczeNLM3zOyvistb+tgF82rK49b039nNbAjwFnAxsA5YAlzr7m82dSIlzGw1MNPdW34AhpmdC/QAj7n7l4rL7gO2uPu9xX+UY9z9b9pkbncBPa3exrvYraij7zbjwJXAdbTwsQvmNZcmPG6teGWfBax093fcfRfwK+CKFsyj7bn7K8CWfS6+Ani0+PpRav9Ymq5kbm3B3Te4++vF19uAvduMt/SxC+bVFK0I+yRgbZ/v19Fe+7078Fsze83M5rd6Mv2Y0GebrY3AhFZOph/JbbybaZ9txtvmsatn+/Oq9AHd58129z8HLgW+U7xdbUte+x2snXqnA9rGu1n62Wb8T1r52NW7/XlVrQj7emByn++PKy5rC+6+vvh7E/A07bcVdffeHXSLvze1eD5/0k7bePe3zTht8Ni1cvvzVoR9CTDVzE4ws8OAbwDPtGAen2Nmw4sPTjCz4cAltN9W1M8A84qv5wG/aeFc/p922ca7bJtxWvzYtXz7c3dv+h/gMmqfyK8C/q4VcyiZ14nAfxd/3mj13IAnqL2t203ts40bgKOBl4G3gd8BY9tobr+gtrX3MmrB6mjR3GZTe4u+DFha/Lms1Y9dMK+mPG46XFYkE/qATiQTCrtIJhR2kUwo7CKZUNhFMqGwi2RCYRfJxP8B54EHfMD//hsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT-Mv5EqgxSF"
      },
      "source": [
        "## DataLoader\n",
        "O Dataloader tem for função gerenciar o carregamento de dados para o treinamento de redes neurais, trazendo diversas funções que auxiliam e otimizam o treino. Entre elas podemos citar:\n",
        "- Embaralhamento dos dados\n",
        "- Separação do dataset em batches\n",
        "- Carregamento de batches em paralelo utilizando threads\n",
        "\n",
        "Todas as funcionalidades citadas são controlados na criação (instanciação) do DataLoader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cAQvNJdlJJ-"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloader_treino = DataLoader(dados_treino, \n",
        "                                batch_size=16, \n",
        "                                shuffle=True, \n",
        "                                num_workers=3)\n",
        "\n",
        "dataloader_teste = DataLoader(dados_teste, \n",
        "                                batch_size=16, \n",
        "                                shuffle=True, \n",
        "                                num_workers=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_rwb0uYq8gW"
      },
      "source": [
        "## CUDA\n",
        "Este pacote adiciona suporte para tipos de tensores CUDA, que implementam a mesma função dos tensores de CPU, mas usam GPUs para computação. <br>\n",
        "Então, basicamente temos GPUs \"disponíveis\" no Colab para poder treinar! Antes de mais nada, habilite a opção para poder utilizar as GPUs do Colab:<br>\n",
        "**Editar -> Configurações de notebook -> Acelerador de hardware -> selecione GPU -> Salvar** <br>\n",
        "Por fim, é preciso ver se temos uma GPU disponível para utilizar:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dqYxVPEsij6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd49227-4243-4b6b-f05a-0430e0ddf4ea"
      },
      "source": [
        "dispositivo = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Usando dispositivo de aceleração de hardware:', dispositivo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Usando dispositivo de aceleração de hardware: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do1VzEpGHaOS"
      },
      "source": [
        "Com isso, para poder rodar nosso modelo na GPU, precisamos enviar as partes pertinentes do nosso modelo para a GPU utilizando o comando ```.to(dispositivo)```. As partes que precisamos enviar para o dispositivo são:\n",
        "- O modelo (ou seja, a rede neural em si);\n",
        "- A função de custo;\n",
        "- Dados e rótulos do batch\n",
        "- Demais dados que serão utilizados, como as predições da rede.\n",
        "\n",
        "Veja um exemplo de enviando o modelo para a GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUcQaFoox5_s"
      },
      "source": [
        "rede = RedeSimples().to(dispositivo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5Xq5zmGJVI2"
      },
      "source": [
        "Por fim, para retornar um determinado dado para a CPU, basta fazer ```.cpu()```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-ehIiletnoL"
      },
      "source": [
        "## Fluxo de Treinamento\n",
        "O fluxo de treinamento de um modelo utilizando o PyTorch, em geral, é bem parecido em todos os casos. Os passos que devem ser executados são:\n",
        "- Definir as funções de custo e o otimizador;\n",
        "- Iterar nas épocas;\n",
        "- Iterar nos batches;\n",
        "- Cast dos dados no dispositivo de hardware (no nosso caso, 'cuda');\n",
        "- Forward na rede e cálculo da loss\n",
        "- Cálculo do gradiente e atualização dos pesos\n",
        "\n",
        "Além disso, é interessante monitorarmos como nossa *loss* e nossa acurácia variam ao longo das épocas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VmzUVUGvK2o"
      },
      "source": [
        "### Definindo as funções de custo e o otimizador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWXU-js_vIOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757d1170-38f1-485f-d67a-edbf264424ac"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Definição da função de custo\n",
        "criterio = nn.CrossEntropyLoss().to(dispositivo)\n",
        "\n",
        "# Definição do otimizador\n",
        "otimizador = optim.Adam(rede.parameters(), lr=0.005)\n",
        "\n",
        "print(\"Função de custo escolhida: \" + str(criterio), end='\\n\\n')\n",
        "print(\"Otimizador escolhido: \" + str(otimizador))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Função de custo escolhida: CrossEntropyLoss()\n",
            "\n",
            "Otimizador escolhido: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.005\n",
            "    weight_decay: 0\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYUFM1GQwUwd"
      },
      "source": [
        "### Loop de Treino"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T869kqDewbLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19bd1fc8-1db8-4de7-9619-190e491120c4"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Definição do número de épocas\n",
        "num_epocas = 10\n",
        "\n",
        "for epoca in range(num_epocas):\n",
        "\n",
        "    batches_loss = []\n",
        "    rotulos = []\n",
        "    predicoes = []\n",
        "    for batch in dataloader_treino:\n",
        "\n",
        "        dado, rotulo = batch\n",
        "\n",
        "        # Casting para a GPU\n",
        "        dado   = dado.to(dispositivo)\n",
        "        rotulo = rotulo.to(dispositivo)\n",
        "\n",
        "        # Forward\n",
        "        pred = rede.forward(dado)\n",
        "        loss = criterio(pred, rotulo)\n",
        "        batches_loss.append(loss.data.cpu())\n",
        "\n",
        "        # Backward\n",
        "        otimizador.zero_grad()\n",
        "        loss.backward()\n",
        "        otimizador.step()\n",
        "\n",
        "        # Armazenamento de valores\n",
        "        valores, indices = torch.max(pred.data.cpu(), -1)\n",
        "        for idx in range(len(indices)):\n",
        "            rotulos.append(rotulo.data.cpu()[idx])\n",
        "            predicoes.append(indices[idx])\n",
        "    \n",
        "    batches_loss = np.asarray(batches_loss)\n",
        "    batches_loss_media = batches_loss.mean()\n",
        "\n",
        "    acuracia = accuracy_score(rotulos, predicoes) * 100\n",
        "\n",
        "    print(\"Epoca %3d | Loss: %4.3f | Acc: %4.2f%%\" % (epoca+1, batches_loss_media, acuracia))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca   1 | Loss: 0.509 | Acc: 80.89%\n",
            "Epoca   2 | Loss: 0.386 | Acc: 85.77%\n",
            "Epoca   3 | Loss: 0.358 | Acc: 86.92%\n",
            "Epoca   4 | Loss: 0.342 | Acc: 87.39%\n",
            "Epoca   5 | Loss: 0.341 | Acc: 87.62%\n",
            "Epoca   6 | Loss: 0.327 | Acc: 87.87%\n",
            "Epoca   7 | Loss: 0.324 | Acc: 88.26%\n",
            "Epoca   8 | Loss: 0.321 | Acc: 88.39%\n",
            "Epoca   9 | Loss: 0.315 | Acc: 88.62%\n",
            "Epoca  10 | Loss: 0.317 | Acc: 88.45%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rphn5ST_69E5"
      },
      "source": [
        "### Avaliando o modelo\n",
        "Por fim, vamos calcular a acurácia do modelo sobre o dataset de teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5xlcj4-7GQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac666d9-c074-4dcf-9c18-28e0beb41b4d"
      },
      "source": [
        "for batch in dataloader_teste:\n",
        "\n",
        "    dado, rotulo = batch\n",
        "\n",
        "    dado   = dado.to(dispositivo)\n",
        "    rotulo = rotulo.to(dispositivo)\n",
        "\n",
        "    pred = rede.forward(dado.to(dispositivo))\n",
        "\n",
        "    valores, indices = torch.max(pred.data.cpu(), -1)\n",
        "    for idx in range(len(indices)):\n",
        "        rotulos.append(rotulo.data.cpu()[idx])\n",
        "        predicoes.append(indices[idx])\n",
        "    \n",
        "acuracia = accuracy_score(rotulos, predicoes) * 100\n",
        "\n",
        "print(\"Acurácia final do modelo: %4.2f%%\" % (acuracia))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia final do modelo: 88.26%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}